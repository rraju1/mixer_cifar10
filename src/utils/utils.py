import numpy as np
import torch
import torch.nn as nn
import warnings
import math

def get_model(args):
    model = None
    if args.model=='mlp_mixer':
        from utils.mlp_mixer import MLPMixer
        model = MLPMixer(
            in_channels=3,
            img_size=args.size,
            hidden_size=args.hidden_size,
            patch_size = args.patch_size,
            hidden_c = args.hidden_c,
            hidden_s = args.hidden_s,
            num_layers = args.num_layers,
            num_classes=args.num_classes,
            drop_p=args.drop_p,
            off_act=args.off_act,
            is_cls_token=args.is_cls_token
        )
    elif args.model=='mlp_mixer_masked':
        from utils.mlp_mixer import MaskedMLPMixer
        model = MaskedMLPMixer(
            in_channels=3,
            img_size=args.size,
            hidden_size=args.hidden_size,
            patch_size = args.patch_size,
            hidden_c = args.hidden_c,
            hidden_s = args.hidden_s,
            num_layers = args.num_layers,
            num_classes=args.num_classes,
            drop_p=args.drop_p,
            off_act=args.off_act,
            is_cls_token=args.is_cls_token
        )
    else:
        raise ValueError(f"No such model: {args.model}")

    return model.to(args.device)

def rand_bbox(size, lam):
    W = size[2]
    H = size[3]
    cut_rat = np.sqrt(1. - lam)
    cut_w = np.int(W * cut_rat)
    cut_h = np.int(H * cut_rat)

    # uniform
    cx = np.random.randint(W)
    cy = np.random.randint(H)

    bbx1 = np.clip(cx - cut_w // 2, 0, W)
    bby1 = np.clip(cy - cut_h // 2, 0, H)
    bbx2 = np.clip(cx + cut_w // 2, 0, W)
    bby2 = np.clip(cy + cut_h // 2, 0, H)

    return bbx1, bby1, bbx2, bby2

def trunc_normal_(tensor, mean=0., std=1., a=-2., b=2.):
    # type: (Tensor, float, float, float, float) -> Tensor
    return _no_grad_trunc_normal_(tensor, mean, std, a, b)

def _no_grad_trunc_normal_(tensor, mean, std, a, b):
    # Cut & paste from PyTorch official master until it's in a few official releases - RW
    # Method based on https://people.sc.fsu.edu/~jburkardt/presentations/truncated_normal.pdf
    def norm_cdf(x):
        # Computes standard normal cumulative distribution function
        return (1. + math.erf(x / math.sqrt(2.))) / 2.

    if (mean < a - 2 * std) or (mean > b + 2 * std):
        warnings.warn("mean is more than 2 std from [a, b] in nn.init.trunc_normal_. "
                      "The distribution of values may be incorrect.",
                      stacklevel=2)

    with torch.no_grad():
        # Values are generated by using a truncated uniform distribution and
        # then using the inverse CDF for the normal distribution.
        # Get upper and lower cdf values
        l = norm_cdf((a - mean) / std)
        u = norm_cdf((b - mean) / std)

        # Uniformly fill tensor with values from [l, u], then translate to
        # [2l-1, 2u-1].
        tensor.uniform_(2 * l - 1, 2 * u - 1)

        # Use inverse cdf transform for normal distribution to get truncated
        # standard normal
        tensor.erfinv_()

        # Transform to proper mean, std
        tensor.mul_(std * math.sqrt(2.))
        tensor.add_(mean)

        # Clamp to ensure it's in the proper range
        tensor.clamp_(min=a, max=b)
        return tensor

def project_bin_mask(image, index, data, lambda_drop, ps, in_chan, hidden):
    A = torch.randn(hidden, in_chan * ps * ps)
    unfold_fn = nn.Unfold(kernel_size=(ps, ps), stride=ps)
    mask = get_mask_batch(image, index, data, lambda_drop)
    patched = gen_mask(mask, unfold_fn)
    output = torch.nn.functional.linear(patched, A, bias=None)
    return output

def get_mask_batch(image, idx, attn_dict, drop_lambda):
    idx_np = idx.numpy()
    w_featmap = int(np.sqrt(len(attn_dict[str(0)]))) # 14 0 is a random key
    h_featmap = int(np.sqrt(len(attn_dict[str(0)]))) # 14
    scale = image.shape[2] // w_featmap # to pass to interpolate
    batch_size = len(idx)

    batch_array = [] # collect attn maps
    for i in range(batch_size):
        batch_array.append(np.array(attn_dict[str(idx_np[i])]))
    batch_tensor = torch.tensor(np.array(batch_array))

    val, indices = torch.sort(batch_tensor, dim=1)
    threshold = torch.quantile(val, drop_lambda, dim=1)
    th_attn = val >= threshold[:,None]
    idx2 = torch.argsort(indices, dim=1) # rearrange patch positions
    for batch_idx in range(th_attn.shape[0]):
        th_attn[batch_idx] = th_attn[batch_idx][idx2[batch_idx]]

    th_attn = th_attn.float() # bool -> float
    bin_mask = th_attn.reshape(-1, w_featmap, h_featmap)
    mask = torch.nn.functional.interpolate(bin_mask.unsqueeze(1), scale_factor=scale, mode="nearest")
    return mask

def gen_mask(masks, unfold_fn):
    patched_tensor = unfold_fn(masks.repeat(1,3,1,1))
    patched_tensor = patched_tensor.permute(0,2,1)
    return patched_tensor